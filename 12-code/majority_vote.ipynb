{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于LLM微调的数学推理任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/autodl-tmp/conda/Base/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import one_hot\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from evaluate import load\n",
    "from datasets import load_dataset\n",
    "\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置代理\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"openai/gsm8k\", \"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(prompt, batch_size=1):\n",
    "    def preprocess(dataset, shuffle=True):\n",
    "        def collate_fn(batch):\n",
    "            questions =  [[{\"role\": \"user\", \"content\": prompt.format(text=item['question'])}] for item in batch]\n",
    "            answers = [item[\"answer\"] for item in batch]\n",
    "            return questions, answers\n",
    "        return DataLoader(\n",
    "            dataset,\n",
    "            shuffle=shuffle,\n",
    "            batch_size=batch_size,\n",
    "            collate_fn=collate_fn,\n",
    "        )\n",
    "    testset = dataset['test']\n",
    "    return preprocess(testset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANS_RE = re.compile(r\"#### (\\-?[0-9\\.\\,]+)\")\n",
    "INVALID_ANS = \"[invalid]\"\n",
    "\n",
    "def extract_answer(answer):\n",
    "    match = ANS_RE.search(answer)\n",
    "    if match:\n",
    "        match_str = match.group(1).strip()\n",
    "        match_str = match_str.replace(\",\", \"\")\n",
    "        return match_str\n",
    "    else:\n",
    "        return INVALID_ANS\n",
    "    \n",
    "def is_correct(reply, truth):\n",
    "    answer = extract_answer(truth)\n",
    "    assert answer != INVALID_ANS\n",
    "    return reply == answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_process(model_name, tokenizer_name, prompt, batch_size=1, ratio=1, result_num=1):\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=\"auto\",\n",
    "        device_map=\"auto\",\n",
    "        cache_dir = '/autodl-tmp/cache'\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    testloader = get_dataloader(prompt, batch_size)\n",
    "    answers = []\n",
    "    replies = [[] for _ in range(result_num)]\n",
    "    # 以下过程参照huggingface上的qwen2.5模型示例\n",
    "    for idx, (texts, truths) in tqdm(enumerate(testloader), total=int(len(testloader) * ratio)):\n",
    "        if idx >= int(len(testloader) * ratio):\n",
    "            break\n",
    "        for i in range(result_num):\n",
    "\n",
    "            texts = [tokenizer.apply_chat_template(\n",
    "                text,\n",
    "                tokenize=False,\n",
    "                add_generation_prompt=True\n",
    "            ) for text in texts]\n",
    "            model_inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, padding_side='left').to(model.device)\n",
    "\n",
    "            generated_ids = model.generate(\n",
    "                **model_inputs,\n",
    "                max_new_tokens=256\n",
    "            )\n",
    "\n",
    "            generated_ids = [\n",
    "                output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "            ]\n",
    "\n",
    "            responses = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "            replies[i].extend(responses)\n",
    "        answers.extend(truths)\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i in range(len(answers)):\n",
    "        total += 1\n",
    "        candidates = []\n",
    "        for j in range(result_num):\n",
    "            candidates.append(extract_answer(replies[j][i]))\n",
    "        from collections import Counter\n",
    "        count = Counter(candidates)\n",
    "        reply = count.most_common(1)[0][0]\n",
    "        answer = answers[i]\n",
    "        correct += is_correct(reply, answer)\n",
    "    print(f\"正确率: {(correct / total) * 100: .2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"output/qwen2_5-0_5b-instruct/v1-20241125-232429/checkpoint-450\"\n",
    "tokenizer_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "\n",
    "prompt = '''You are a highly skilled mathematician capable of solving complex grade-school math problems step by step. Please read the problem carefully and solve it with clear reasoning. Follow these instructions:\n",
    "\n",
    "- Identify the known information and the question being asked.\n",
    "- Break the solution into logical steps, providing clear explanations for each.\n",
    "- Show all calculations and intermediate results.\n",
    "- Conclude with a final answer.\n",
    "\n",
    "Output your response in the following format:\n",
    "[Explanation and calculations]\n",
    "#### [Final numerical answer]   \n",
    "\n",
    "Here is the problem:\n",
    "{text}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [01:51<00:00,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正确率:  29.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_process(model_name, tokenizer_name, prompt, batch_size=8, ratio=0.1, result_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [05:16<00:00, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正确率:  0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_process(model_name, tokenizer_name, prompt, batch_size=8, ratio=0.1, result_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [09:43<00:00, 36.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正确率:  0.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_process(model_name, tokenizer_name, prompt, batch_size=8, ratio=0.1, result_num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/autodl-tmp/conda/Base/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[INFO:swift] Successfully registered `/autodl-tmp/conda/Base/lib/python3.10/site-packages/swift/llm/data/dataset_info.json`\n",
      "[INFO:swift] No vLLM installed, if you are using vLLM, you will get `ImportError: cannot import name 'get_vllm_engine' from 'swift.llm'`\n",
      "[INFO:swift] No LMDeploy installed, if you are using LMDeploy, you will get `ImportError: cannot import name 'prepare_lmdeploy_engine_template' from 'swift.llm'`\n"
     ]
    }
   ],
   "source": [
    "# 导入swift框架进行微调\n",
    "from swift.llm import (\n",
    "    DatasetName, InferArguments, ModelType, SftArguments,\n",
    "    infer_main, sft_main, app_ui_main\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:swift] Setting template_type: qwen2_5\n",
      "[INFO:swift] Setting args.lazy_tokenize: False\n",
      "[INFO:swift] Setting args.dataloader_num_workers: 1\n",
      "[INFO:swift] output_dir: /root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429\n",
      "[INFO:swift] Start time of running main: 2024-11-25 23:24:29.426308\n",
      "[INFO:swift] args: SftArguments(model_type='qwen2_5-0_5b-instruct', model_id_or_path='qwen/Qwen2.5-0.5B-Instruct', model_revision='master', full_determinism=False, sft_type='lora', freeze_parameters=[], freeze_vit=False, freeze_parameters_ratio=0.0, additional_trainable_parameters=[], tuner_backend='peft', template_type='qwen2_5', output_dir='/root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429', add_output_dir_suffix=True, ddp_backend=None, ddp_find_unused_parameters=None, ddp_broadcast_buffers=None, ddp_timeout=1800, seed=42, resume_from_checkpoint=None, resume_only_model=False, ignore_data_skip=False, dtype='bf16', packing=False, train_backend='transformers', tp=1, pp=1, min_lr=None, sequence_parallel=False, model_kwargs={}, loss_name=None, dataset=['gsm8k-train.jsonl'], val_dataset=[], dataset_seed=42, dataset_test_ratio=0.01, use_loss_scale=False, loss_scale_config_path='/autodl-tmp/conda/Base/lib/python3.10/site-packages/swift/llm/agent/default_loss_scale_config.json', system=None, tools_prompt='react_en', max_length=4096, truncation_strategy='delete', check_dataset_strategy='none', streaming=False, streaming_val_size=0, streaming_buffer_size=16384, model_name=[None, None], model_author=[None, None], quant_method=None, quantization_bit=0, hqq_axis=0, hqq_dynamic_config_path=None, bnb_4bit_comp_dtype='bf16', bnb_4bit_quant_type='nf4', bnb_4bit_use_double_quant=True, bnb_4bit_quant_storage=None, rescale_image=-1, target_modules=['q_proj', 'k_proj', 'v_proj'], target_regex=None, modules_to_save=[], lora_rank=8, lora_alpha=32, lora_dropout=0.05, lora_bias_trainable='none', lora_dtype='AUTO', lora_lr_ratio=None, use_rslora=False, use_dora=False, init_lora_weights='true', fourier_n_frequency=2000, fourier_scaling=300.0, rope_scaling=None, boft_block_size=4, boft_block_num=0, boft_n_butterfly_factor=1, boft_dropout=0.0, vera_rank=256, vera_projection_prng_key=0, vera_dropout=0.0, vera_d_initial=0.1, adapter_act='gelu', adapter_length=128, use_galore=False, galore_target_modules=None, galore_rank=128, galore_update_proj_gap=50, galore_scale=1.0, galore_proj_type='std', galore_optim_per_parameter=False, galore_with_embedding=False, galore_quantization=False, galore_proj_quant=False, galore_proj_bits=4, galore_proj_group_size=256, galore_cos_threshold=0.4, galore_gamma_proj=2, galore_queue_size=5, adalora_target_r=8, adalora_init_r=12, adalora_tinit=0, adalora_tfinal=0, adalora_deltaT=1, adalora_beta1=0.85, adalora_beta2=0.85, adalora_orth_reg_weight=0.5, ia3_feedforward_modules=[], llamapro_num_new_blocks=4, llamapro_num_groups=None, neftune_noise_alpha=None, neftune_backend='transformers', lisa_activated_layers=0, lisa_step_interval=20, reft_layer_key=None, reft_layers=None, reft_rank=4, reft_intervention_type='LoreftIntervention', reft_args=None, use_liger=False, gradient_checkpointing=True, vit_use_gc=True, deepspeed=None, batch_size=1, eval_batch_size=1, auto_find_batch_size=False, num_train_epochs=1, max_steps=-1, optim='adamw_torch', adam_beta1=0.9, adam_beta2=0.95, adam_epsilon=1e-08, learning_rate=0.0001, weight_decay=0.1, gradient_accumulation_steps=16, max_grad_norm=1, predict_with_generate=False, lr_scheduler_type='cosine', lr_scheduler_kwargs={}, warmup_ratio=0.05, warmup_steps=0, eval_steps=50, save_steps=50, save_only_model=False, save_total_limit=2, logging_steps=5, acc_steps=1, dataloader_num_workers=1, dataloader_pin_memory=True, dataloader_drop_last=False, push_to_hub=False, hub_model_id=None, hub_token=None, hub_private_repo=False, hub_strategy='every_save', test_oom_error=False, disable_tqdm=False, lazy_tokenize=False, preprocess_num_proc=1, use_flash_attn=None, ignore_args_error=False, check_model_is_latest=True, logging_dir='/root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429/runs', report_to=['tensorboard'], acc_strategy='token', save_on_each_node=False, evaluation_strategy='steps', save_strategy='steps', save_safetensors=True, gpu_memory_fraction=None, include_num_input_tokens_seen=False, local_repo_path=None, custom_register_path=None, custom_dataset_info=None, device_map_config=None, device_max_memory=[], max_new_tokens=2048, do_sample=None, temperature=None, top_k=None, top_p=None, repetition_penalty=None, num_beams=1, fsdp='', fsdp_config=None, sequence_parallel_size=1, model_layer_cls_name=None, metric_warmup_step=0, fsdp_num=1, per_device_train_batch_size=None, per_device_eval_batch_size=None, eval_strategy=None, self_cognition_sample=0, train_dataset_mix_ratio=0.0, train_dataset_mix_ds=['ms-bench'], train_dataset_sample=-1, val_dataset_sample=None, safe_serialization=None, only_save_model=None, neftune_alpha=None, deepspeed_config_path=None, model_cache_dir=None, lora_dropout_p=None, lora_target_modules=[], lora_target_regex=None, lora_modules_to_save=[], boft_target_modules=[], boft_modules_to_save=[], vera_target_modules=[], vera_modules_to_save=[], ia3_target_modules=[], ia3_modules_to_save=[], custom_train_dataset_path=[], custom_val_dataset_path=[], device_map_config_path=None, push_hub_strategy=None)\n",
      "[INFO:swift] Global seed set to 42\n",
      "[INFO:swift] Downloading the model from ModelScope Hub, model_id: qwen/Qwen2.5-0.5B-Instruct\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_count: 1\n",
      "rank: -1, local_rank: -1, world_size: 1, local_world_size: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING:modelscope] Using branch: master as version is unstable, use with caution\n",
      "[INFO:swift] Loading the model using model_dir: /root/.cache/modelscope/hub/qwen/Qwen2___5-0___5B-Instruct\n",
      "[INFO:swift] model_kwargs: {'device_map': 'cuda:0'}\n",
      "[INFO:swift] model.max_model_len: 32768\n",
      "[INFO:swift] model.hf_device_map: {'': device(type='cuda', index=0)}\n",
      "[INFO:swift] model_config: Qwen2Config {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"_name_or_path\": \"/root/.cache/modelscope/hub/qwen/Qwen2___5-0___5B-Instruct\",\n",
      "  \"architectures\": [\n",
      "    \"Qwen2ForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 896,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4864,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"max_window_layers\": 21,\n",
      "  \"model_type\": \"qwen2\",\n",
      "  \"num_attention_heads\": 14,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_key_value_heads\": 2,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 1000000.0,\n",
      "  \"sliding_window\": null,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.46.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_sliding_window\": false,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO:swift] model.generation_config: GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"max_new_tokens\": 2048,\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"repetition_penalty\": 1.1,\n",
      "  \"temperature\": 0.7,\n",
      "  \"top_k\": 20,\n",
      "  \"top_p\": 0.8\n",
      "}\n",
      "\n",
      "[INFO:swift] Setting model.config.use_cache: False\n",
      "[INFO:swift] target_modules: ['q_proj', 'k_proj', 'v_proj']\n",
      "[INFO:swift] modules_to_save: []\n",
      "[INFO:swift] lora_config: get_wrapped_class.<locals>.PeftWrapper(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path='/root/.cache/modelscope/hub/qwen/Qwen2___5-0___5B-Instruct', revision=None, task_type='CAUSAL_LM', inference_mode=False, r=8, target_modules={'q_proj', 'k_proj', 'v_proj'}, lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=[], init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_dtype=None, lorap_lr_ratio=None, lorap_emb_lr=1e-06)\n",
      "[INFO:swift] [base_model.model.model.embed_tokens.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.model.layers.0.self_attn.q_proj.base_layer.bias]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight]: requires_grad=True, dtype=torch.float32, device=cuda:0\n",
      "[INFO:swift] [base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight]: requires_grad=True, dtype=torch.float32, device=cuda:0\n",
      "[INFO:swift] [base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.model.layers.0.self_attn.k_proj.base_layer.bias]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight]: requires_grad=True, dtype=torch.float32, device=cuda:0\n",
      "[INFO:swift] [base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight]: requires_grad=True, dtype=torch.float32, device=cuda:0\n",
      "[INFO:swift] [base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.model.layers.0.self_attn.v_proj.base_layer.bias]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight]: requires_grad=True, dtype=torch.float32, device=cuda:0\n",
      "[INFO:swift] [base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight]: requires_grad=True, dtype=torch.float32, device=cuda:0\n",
      "[INFO:swift] [base_model.model.model.layers.0.self_attn.o_proj.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.model.layers.0.mlp.gate_proj.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.model.layers.0.mlp.up_proj.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.model.layers.0.mlp.down_proj.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.model.layers.0.input_layernorm.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.model.layers.0.post_attention_layernorm.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] [base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight]: requires_grad=False, dtype=torch.bfloat16, device=cuda:0\n",
      "[INFO:swift] ...\n",
      "[INFO:swift] PeftModelForCausalLM(\n",
      "  (base_model): LoraModel(\n",
      "    (model): Qwen2ForCausalLM(\n",
      "      (model): Qwen2Model(\n",
      "        (embed_tokens): Embedding(151936, 896)\n",
      "        (layers): ModuleList(\n",
      "          (0-23): 24 x Qwen2DecoderLayer(\n",
      "            (self_attn): Qwen2SdpaAttention(\n",
      "              (q_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=896, out_features=896, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=896, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=896, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (k_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=896, out_features=128, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=896, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=128, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (v_proj): lora.Linear(\n",
      "                (base_layer): Linear(in_features=896, out_features=128, bias=True)\n",
      "                (lora_dropout): ModuleDict(\n",
      "                  (default): Dropout(p=0.05, inplace=False)\n",
      "                )\n",
      "                (lora_A): ModuleDict(\n",
      "                  (default): Linear(in_features=896, out_features=8, bias=False)\n",
      "                )\n",
      "                (lora_B): ModuleDict(\n",
      "                  (default): Linear(in_features=8, out_features=128, bias=False)\n",
      "                )\n",
      "                (lora_embedding_A): ParameterDict()\n",
      "                (lora_embedding_B): ParameterDict()\n",
      "                (lora_magnitude_vector): ModuleDict()\n",
      "              )\n",
      "              (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
      "              (rotary_emb): Qwen2RotaryEmbedding()\n",
      "            )\n",
      "            (mlp): Qwen2MLP(\n",
      "              (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "              (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
      "              (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "            (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "            (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "          )\n",
      "        )\n",
      "        (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
      "        (rotary_emb): Qwen2RotaryEmbedding()\n",
      "      )\n",
      "      (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[INFO:swift] PeftModelForCausalLM: 494.7700M Params (0.7373M Trainable [0.1490%]), 0.0008M Buffers.\n",
      "[INFO:swift] system: You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\n",
      "[INFO:swift] args.lazy_tokenize: False\n",
      "[INFO:swift] train_dataset: Dataset({\n",
      "    features: ['query', 'response'],\n",
      "    num_rows: 7399\n",
      "})\n",
      "[INFO:swift] val_dataset: Dataset({\n",
      "    features: ['query', 'response'],\n",
      "    num_rows: 74\n",
      "})\n",
      "[INFO:swift] [INPUT_IDS] [151644, 8948, 198, 2610, 525, 1207, 16948, 11, 3465, 553, 54364, 14817, 13, 1446, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 2610, 525, 264, 7548, 25530, 20976, 1103, 12875, 315, 21828, 6351, 11972, 34689, 6888, 5322, 3019, 553, 3019, 13, 5209, 1349, 279, 3491, 15516, 323, 11625, 432, 448, 2797, 32711, 13, 11112, 1493, 11221, 1447, 12, 64547, 279, 3881, 1995, 323, 279, 3405, 1660, 4588, 624, 12, 15623, 279, 6291, 1119, 19819, 7354, 11, 8241, 2797, 40841, 369, 1817, 624, 12, 6928, 678, 28117, 323, 28439, 3059, 624, 12, 1200, 857, 448, 264, 1590, 4226, 382, 5097, 697, 2033, 304, 279, 2701, 3561, 510, 58, 69769, 323, 28117, 921, 820, 508, 19357, 34776, 4226, 60, 33933, 8420, 374, 279, 3491, 510, 3862, 1033, 220, 23, 15, 15, 15, 51341, 26896, 304, 264, 3654, 20311, 11, 323, 220, 16, 15, 1251, 31293, 705, 311, 1896, 1045, 13, 576, 1156, 4743, 1251, 1817, 3867, 10917, 438, 1657, 51341, 26896, 438, 1817, 315, 279, 1537, 3040, 1251, 3867, 13, 1416, 279, 1537, 3040, 1251, 1817, 3867, 220, 19, 15, 15, 51341, 26896, 11, 1246, 1657, 51341, 26896, 14616, 304, 279, 5476, 30, 151645, 198, 151644, 77091, 198, 2679, 279, 1537, 3040, 1251, 1817, 3867, 220, 19, 15, 15, 51341, 26896, 11, 807, 3867, 264, 2790, 315, 220, 19, 9, 19, 15, 15, 284, 1115, 19, 9, 19, 15, 15, 28, 16, 21, 15, 15, 2452, 16, 21, 15, 15, 51341, 26896, 624, 785, 1156, 4743, 1251, 1817, 3867, 10917, 438, 1657, 51341, 26896, 438, 1817, 315, 279, 1537, 3040, 1251, 3867, 11, 7290, 1817, 315, 1105, 3867, 220, 17, 9, 19, 15, 15, 284, 1115, 17, 9, 19, 15, 15, 28, 23, 15, 15, 2452, 23, 15, 15, 51341, 26896, 624, 785, 2790, 1372, 315, 51341, 26896, 279, 1156, 4743, 1251, 3867, 374, 220, 23, 15, 15, 9, 21, 284, 1115, 23, 15, 15, 9, 21, 28, 19, 23, 15, 15, 2452, 19, 23, 15, 15, 51341, 26896, 624, 80987, 11, 678, 220, 16, 15, 1251, 3867, 3786, 220, 19, 23, 15, 15, 10, 16, 21, 15, 15, 284, 1115, 19, 23, 15, 15, 10, 16, 21, 15, 15, 28, 21, 19, 15, 15, 2452, 21, 19, 15, 15, 51341, 26896, 624, 2679, 1052, 1033, 220, 23, 15, 15, 15, 51341, 26896, 304, 264, 3654, 20311, 11, 279, 1372, 315, 51341, 26896, 429, 14616, 374, 220, 23, 15, 15, 15, 12, 21, 19, 15, 15, 28, 1115, 23, 15, 15, 15, 12, 21, 19, 15, 15, 28, 16, 21, 15, 15, 2452, 16, 21, 15, 15, 198, 820, 220, 16, 21, 15, 15, 151645]\n",
      "[INFO:swift] [INPUT] <|im_start|>system\n",
      "You are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "You are a highly skilled mathematician capable of solving complex grade-school math problems step by step. Please read the problem carefully and solve it with clear reasoning. Follow these instructions:\n",
      "\n",
      "- Identify the known information and the question being asked.\n",
      "- Break the solution into logical steps, providing clear explanations for each.\n",
      "- Show all calculations and intermediate results.\n",
      "- Conclude with a final answer.\n",
      "\n",
      "Output your response in the following format:\n",
      "[Explanation and calculations]\n",
      "#### [Final numerical answer]   \n",
      "\n",
      "Here is the problem:\n",
      "There were 8000 jelly beans in a certain barrel, and 10 people lined up to take some. The first six people each took twice as many jelly beans as each of the last four people took. If the last four people each took 400 jelly beans, how many jelly beans remained in the container?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "If the last four people each took 400 jelly beans, they took a total of 4*400 = <<4*400=1600>>1600 jelly beans.\n",
      "The first six people each took twice as many jelly beans as each of the last four people took, meaning each of them took 2*400 = <<2*400=800>>800 jelly beans.\n",
      "The total number of jelly beans the first six people took is 800*6 = <<800*6=4800>>4800 jelly beans.\n",
      "Together, all 10 people took together 4800+1600 = <<4800+1600=6400>>6400 jelly beans.\n",
      "If there were 8000 jelly beans in a certain barrel, the number of jelly beans that remained is 8000-6400= <<8000-6400=1600>>1600\n",
      "#### 1600<|im_end|>\n",
      "[INFO:swift] [LABELS_IDS] [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 2679, 279, 1537, 3040, 1251, 1817, 3867, 220, 19, 15, 15, 51341, 26896, 11, 807, 3867, 264, 2790, 315, 220, 19, 9, 19, 15, 15, 284, 1115, 19, 9, 19, 15, 15, 28, 16, 21, 15, 15, 2452, 16, 21, 15, 15, 51341, 26896, 624, 785, 1156, 4743, 1251, 1817, 3867, 10917, 438, 1657, 51341, 26896, 438, 1817, 315, 279, 1537, 3040, 1251, 3867, 11, 7290, 1817, 315, 1105, 3867, 220, 17, 9, 19, 15, 15, 284, 1115, 17, 9, 19, 15, 15, 28, 23, 15, 15, 2452, 23, 15, 15, 51341, 26896, 624, 785, 2790, 1372, 315, 51341, 26896, 279, 1156, 4743, 1251, 3867, 374, 220, 23, 15, 15, 9, 21, 284, 1115, 23, 15, 15, 9, 21, 28, 19, 23, 15, 15, 2452, 19, 23, 15, 15, 51341, 26896, 624, 80987, 11, 678, 220, 16, 15, 1251, 3867, 3786, 220, 19, 23, 15, 15, 10, 16, 21, 15, 15, 284, 1115, 19, 23, 15, 15, 10, 16, 21, 15, 15, 28, 21, 19, 15, 15, 2452, 21, 19, 15, 15, 51341, 26896, 624, 2679, 1052, 1033, 220, 23, 15, 15, 15, 51341, 26896, 304, 264, 3654, 20311, 11, 279, 1372, 315, 51341, 26896, 429, 14616, 374, 220, 23, 15, 15, 15, 12, 21, 19, 15, 15, 28, 1115, 23, 15, 15, 15, 12, 21, 19, 15, 15, 28, 16, 21, 15, 15, 2452, 16, 21, 15, 15, 198, 820, 220, 16, 21, 15, 15, 151645]\n",
      "[INFO:swift] [LABELS] [-100 * 198]If the last four people each took 400 jelly beans, they took a total of 4*400 = <<4*400=1600>>1600 jelly beans.\n",
      "The first six people each took twice as many jelly beans as each of the last four people took, meaning each of them took 2*400 = <<2*400=800>>800 jelly beans.\n",
      "The total number of jelly beans the first six people took is 800*6 = <<800*6=4800>>4800 jelly beans.\n",
      "Together, all 10 people took together 4800+1600 = <<4800+1600=6400>>6400 jelly beans.\n",
      "If there were 8000 jelly beans in a certain barrel, the number of jelly beans that remained is 8000-6400= <<8000-6400=1600>>1600\n",
      "#### 1600<|im_end|>\n",
      "Map: 100%|██████████| 7399/7399 [00:08<00:00, 865.20it/s]\n",
      "Map: 100%|██████████| 74/74 [00:00<00:00, 856.12it/s]\n",
      "[INFO:swift] Dataset Token Length: 312.371266±67.457570, min=195.000000, max=667.000000, size=7399\n",
      "[INFO:swift] Dataset Token Length: 319.364865±79.672569, min=206.000000, max=556.000000, size=74\n",
      "[INFO:swift] training_args: Seq2SeqTrainingArguments(\n",
      "_n_gpu=1,\n",
      "acc_strategy=token,\n",
      "accelerator_config={'split_batches': False, 'dispatch_batches': False, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.95,\n",
      "adam_epsilon=1e-08,\n",
      "additional_saved_files=[],\n",
      "auto_find_batch_size=False,\n",
      "average_tokens_across_devices=False,\n",
      "batch_eval_metrics=False,\n",
      "bf16=True,\n",
      "bf16_full_eval=False,\n",
      "data_seed=42,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=1,\n",
      "dataloader_persistent_workers=False,\n",
      "dataloader_pin_memory=True,\n",
      "dataloader_prefetch_factor=None,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "dispatch_batches=None,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_do_concat_batches=True,\n",
      "eval_on_start=False,\n",
      "eval_steps=50,\n",
      "eval_strategy=steps,\n",
      "eval_use_gather_object=False,\n",
      "evaluation_strategy=None,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "generation_config=GenerationConfig {\n",
      "  \"bos_token_id\": 151643,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 151645,\n",
      "  \"max_new_tokens\": 2048,\n",
      "  \"pad_token_id\": 151643,\n",
      "  \"repetition_penalty\": 1.1,\n",
      "  \"temperature\": 0.7,\n",
      "  \"top_k\": 20,\n",
      "  \"top_p\": 0.8\n",
      "}\n",
      ",\n",
      "generation_max_length=None,\n",
      "generation_num_beams=None,\n",
      "gradient_accumulation_steps=16,\n",
      "gradient_checkpointing=True,\n",
      "gradient_checkpointing_kwargs=None,\n",
      "greater_is_better=False,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_always_push=False,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_for_metrics=[],\n",
      "include_inputs_for_metrics=False,\n",
      "include_num_input_tokens_seen=False,\n",
      "include_tokens_per_second=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429/runs,\n",
      "logging_first_step=True,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=5,\n",
      "logging_strategy=steps,\n",
      "loss_name=None,\n",
      "lr_scheduler_kwargs={},\n",
      "lr_scheduler_type=cosine,\n",
      "max_grad_norm=1,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=loss,\n",
      "metric_warmup_step=0,\n",
      "mp_parameters=,\n",
      "neftune_noise_alpha=None,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1,\n",
      "optim=adamw_torch,\n",
      "optim_args=None,\n",
      "optim_target_modules=None,\n",
      "output_dir=/root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=1,\n",
      "per_device_train_batch_size=1,\n",
      "predict_with_generate=False,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=False,\n",
      "report_to=['tensorboard'],\n",
      "restore_callback_states_from_checkpoint=False,\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429,\n",
      "save_on_each_node=False,\n",
      "save_only_model=False,\n",
      "save_safetensors=True,\n",
      "save_steps=50,\n",
      "save_strategy=steps,\n",
      "save_total_limit=2,\n",
      "seed=42,\n",
      "skip_memory_metrics=True,\n",
      "sortish_sampler=False,\n",
      "split_batches=None,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torch_empty_cache_steps=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "train_dataset_sample=-1,\n",
      "train_sampler_random=True,\n",
      "use_cpu=False,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_liger_kernel=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.05,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.1,\n",
      ")\n",
      "/autodl-tmp/conda/Base/lib/python3.10/site-packages/swift/trainers/mixin.py:93: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  super().__init__(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "[INFO:swift] The SftArguments will be saved in: /root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429/sft_args.json\n",
      "[INFO:swift] The Seq2SeqTrainingArguments will be saved in: /root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429/training_args.json\n",
      "[INFO:swift] The logging file will be saved in: /root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429/logging.jsonl\n",
      "Train:   0%|          | 1/462 [00:04<34:19,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.61197513, 'acc': 0.85235035, 'grad_norm': 3.15869617, 'learning_rate': 4.17e-06, 'memory(GiB)': 3.21, 'train_speed(iter/s)': 0.202167, 'epoch': 0.0, 'global_step/max_steps': '1/462', 'percentage': '0.22%', 'elapsed_time': '4s', 'remaining_time': '35m 29s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   1%|          | 5/462 [00:15<22:23,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.68376583, 'acc': 0.82469958, 'grad_norm': 2.84423923, 'learning_rate': 2.083e-05, 'memory(GiB)': 6.4, 'train_speed(iter/s)': 0.307612, 'epoch': 0.01, 'global_step/max_steps': '5/462', 'percentage': '1.08%', 'elapsed_time': '15s', 'remaining_time': '24m 13s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   2%|▏         | 10/462 [00:29<21:07,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.65204229, 'acc': 0.83305178, 'grad_norm': 2.19942641, 'learning_rate': 4.167e-05, 'memory(GiB)': 8.23, 'train_speed(iter/s)': 0.330452, 'epoch': 0.02, 'global_step/max_steps': '10/462', 'percentage': '2.16%', 'elapsed_time': '29s', 'remaining_time': '22m 32s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   3%|▎         | 15/462 [00:43<20:44,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.61694822, 'acc': 0.84145708, 'grad_norm': 2.2097621, 'learning_rate': 6.25e-05, 'memory(GiB)': 8.23, 'train_speed(iter/s)': 0.339328, 'epoch': 0.03, 'global_step/max_steps': '15/462', 'percentage': '3.25%', 'elapsed_time': '43s', 'remaining_time': '21m 47s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   4%|▍         | 20/462 [00:57<20:18,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.58666663, 'acc': 0.8430233, 'grad_norm': 1.22232699, 'learning_rate': 8.333e-05, 'memory(GiB)': 8.23, 'train_speed(iter/s)': 0.344239, 'epoch': 0.04, 'global_step/max_steps': '20/462', 'percentage': '4.33%', 'elapsed_time': '57s', 'remaining_time': '21m 16s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   5%|▌         | 25/462 [01:11<20:08,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.53799725, 'acc': 0.85153818, 'grad_norm': 0.98092151, 'learning_rate': 0.0001, 'memory(GiB)': 8.23, 'train_speed(iter/s)': 0.346866, 'epoch': 0.05, 'global_step/max_steps': '25/462', 'percentage': '5.41%', 'elapsed_time': '1m 11s', 'remaining_time': '20m 53s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   6%|▋         | 30/462 [01:25<20:10,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.54924064, 'acc': 0.84976196, 'grad_norm': 1.02524292, 'learning_rate': 9.995e-05, 'memory(GiB)': 8.56, 'train_speed(iter/s)': 0.348136, 'epoch': 0.06, 'global_step/max_steps': '30/462', 'percentage': '6.49%', 'elapsed_time': '1m 25s', 'remaining_time': '20m 37s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   8%|▊         | 35/462 [01:39<19:50,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.47256923, 'acc': 0.86476908, 'grad_norm': 0.80619228, 'learning_rate': 9.984e-05, 'memory(GiB)': 2.25, 'train_speed(iter/s)': 0.34919, 'epoch': 0.08, 'global_step/max_steps': '35/462', 'percentage': '7.58%', 'elapsed_time': '1m 39s', 'remaining_time': '20m 18s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   9%|▊         | 40/462 [01:53<19:33,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.44885225, 'acc': 0.87634258, 'grad_norm': 0.97581089, 'learning_rate': 9.967e-05, 'memory(GiB)': 2.25, 'train_speed(iter/s)': 0.350191, 'epoch': 0.09, 'global_step/max_steps': '40/462', 'percentage': '8.66%', 'elapsed_time': '1m 53s', 'remaining_time': '20m 1s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  10%|▉         | 45/462 [02:08<19:26,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.47702298, 'acc': 0.86619434, 'grad_norm': 1.0663271, 'learning_rate': 9.943e-05, 'memory(GiB)': 2.25, 'train_speed(iter/s)': 0.350685, 'epoch': 0.1, 'global_step/max_steps': '45/462', 'percentage': '9.74%', 'elapsed_time': '2m 7s', 'remaining_time': '19m 45s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  11%|█         | 50/462 [02:21<19:06,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.45771489, 'acc': 0.87052937, 'grad_norm': 0.91966009, 'learning_rate': 9.913e-05, 'memory(GiB)': 2.25, 'train_speed(iter/s)': 0.351409, 'epoch': 0.11, 'global_step/max_steps': '50/462', 'percentage': '10.82%', 'elapsed_time': '2m 21s', 'remaining_time': '19m 29s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100%|██████████| 74/74 [00:04<00:00, 18.20it/s]it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.47185791, 'eval_acc': 0.86164426, 'eval_runtime': 4.0512, 'eval_samples_per_second': 18.266, 'eval_steps_per_second': 18.266, 'epoch': 0.11, 'global_step/max_steps': '50/462', 'percentage': '10.82%', 'elapsed_time': '2m 26s', 'remaining_time': '20m 4s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "[INFO:swift] Saving model checkpoint to /root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429/checkpoint-50\n",
      "Train:  12%|█▏        | 55/462 [02:41<21:32,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.46087322, 'acc': 0.87051802, 'grad_norm': 1.02117682, 'learning_rate': 9.877e-05, 'memory(GiB)': 2.25, 'train_speed(iter/s)': 0.340924, 'epoch': 0.12, 'global_step/max_steps': '55/462', 'percentage': '11.90%', 'elapsed_time': '2m 40s', 'remaining_time': '19m 51s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  13%|█▎        | 60/462 [02:55<19:00,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.46935225, 'acc': 0.86795778, 'grad_norm': 0.9024871, 'learning_rate': 9.834e-05, 'memory(GiB)': 2.25, 'train_speed(iter/s)': 0.34226, 'epoch': 0.13, 'global_step/max_steps': '60/462', 'percentage': '12.99%', 'elapsed_time': '2m 55s', 'remaining_time': '19m 32s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  14%|█▍        | 65/462 [03:09<18:26,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.44819369, 'acc': 0.87220449, 'grad_norm': 0.94080293, 'learning_rate': 9.785e-05, 'memory(GiB)': 2.25, 'train_speed(iter/s)': 0.343261, 'epoch': 0.14, 'global_step/max_steps': '65/462', 'percentage': '14.07%', 'elapsed_time': '3m 9s', 'remaining_time': '19m 14s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  15%|█▌        | 70/462 [03:23<18:34,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.45091658, 'acc': 0.87489376, 'grad_norm': 0.76448703, 'learning_rate': 9.73e-05, 'memory(GiB)': 2.25, 'train_speed(iter/s)': 0.343683, 'epoch': 0.15, 'global_step/max_steps': '70/462', 'percentage': '15.15%', 'elapsed_time': '3m 23s', 'remaining_time': '18m 58s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  16%|█▌        | 75/462 [03:37<18:14,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.44608216, 'acc': 0.8660264, 'grad_norm': 0.92078537, 'learning_rate': 9.669e-05, 'memory(GiB)': 2.25, 'train_speed(iter/s)': 0.344105, 'epoch': 0.16, 'global_step/max_steps': '75/462', 'percentage': '16.23%', 'elapsed_time': '3m 37s', 'remaining_time': '18m 42s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  17%|█▋        | 80/462 [03:51<17:52,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.44821129, 'acc': 0.87080097, 'grad_norm': 0.94582897, 'learning_rate': 9.602e-05, 'memory(GiB)': 3.25, 'train_speed(iter/s)': 0.344694, 'epoch': 0.17, 'global_step/max_steps': '80/462', 'percentage': '17.32%', 'elapsed_time': '3m 51s', 'remaining_time': '18m 26s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  18%|█▊        | 85/462 [04:05<17:36,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.47013569, 'acc': 0.86901646, 'grad_norm': 0.74878061, 'learning_rate': 9.529e-05, 'memory(GiB)': 3.25, 'train_speed(iter/s)': 0.345246, 'epoch': 0.18, 'global_step/max_steps': '85/462', 'percentage': '18.40%', 'elapsed_time': '4m 5s', 'remaining_time': '18m 10s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  19%|█▉        | 90/462 [04:19<17:17,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.43488936, 'acc': 0.86879435, 'grad_norm': 0.84726042, 'learning_rate': 9.45e-05, 'memory(GiB)': 3.25, 'train_speed(iter/s)': 0.345882, 'epoch': 0.19, 'global_step/max_steps': '90/462', 'percentage': '19.48%', 'elapsed_time': '4m 19s', 'remaining_time': '17m 54s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  21%|██        | 95/462 [04:33<16:59,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.46490049, 'acc': 0.87071428, 'grad_norm': 0.93968445, 'learning_rate': 9.366e-05, 'memory(GiB)': 3.25, 'train_speed(iter/s)': 0.346499, 'epoch': 0.21, 'global_step/max_steps': '95/462', 'percentage': '20.56%', 'elapsed_time': '4m 33s', 'remaining_time': '17m 37s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  22%|██▏       | 100/462 [04:47<16:43,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.41392817, 'acc': 0.87934923, 'grad_norm': 0.89749056, 'learning_rate': 9.275e-05, 'memory(GiB)': 3.25, 'train_speed(iter/s)': 0.347046, 'epoch': 0.22, 'global_step/max_steps': '100/462', 'percentage': '21.65%', 'elapsed_time': '4m 47s', 'remaining_time': '17m 21s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100%|██████████| 74/74 [00:03<00:00, 21.14it/s]/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4542239, 'eval_acc': 0.86626296, 'eval_runtime': 3.5, 'eval_samples_per_second': 21.143, 'eval_steps_per_second': 21.143, 'epoch': 0.22, 'global_step/max_steps': '100/462', 'percentage': '21.65%', 'elapsed_time': '4m 51s', 'remaining_time': '17m 35s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "[INFO:swift] Saving model checkpoint to /root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429/checkpoint-100\n",
      "Train:  23%|██▎       | 105/462 [05:06<18:14,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.42202902, 'acc': 0.88121691, 'grad_norm': 0.84174085, 'learning_rate': 9.18e-05, 'memory(GiB)': 3.25, 'train_speed(iter/s)': 0.3427, 'epoch': 0.23, 'global_step/max_steps': '105/462', 'percentage': '22.73%', 'elapsed_time': '5m 6s', 'remaining_time': '17m 20s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  24%|██▍       | 110/462 [05:20<16:41,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.45957813, 'acc': 0.87050238, 'grad_norm': 0.82862681, 'learning_rate': 9.079e-05, 'memory(GiB)': 3.25, 'train_speed(iter/s)': 0.343285, 'epoch': 0.24, 'global_step/max_steps': '110/462', 'percentage': '23.81%', 'elapsed_time': '5m 20s', 'remaining_time': '17m 4s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  25%|██▍       | 115/462 [05:34<16:31,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4728725, 'acc': 0.86399555, 'grad_norm': 0.89626223, 'learning_rate': 8.972e-05, 'memory(GiB)': 3.25, 'train_speed(iter/s)': 0.343477, 'epoch': 0.25, 'global_step/max_steps': '115/462', 'percentage': '24.89%', 'elapsed_time': '5m 34s', 'remaining_time': '16m 49s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  26%|██▌       | 120/462 [05:48<15:59,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.44849319, 'acc': 0.8743638, 'grad_norm': 0.8927837, 'learning_rate': 8.861e-05, 'memory(GiB)': 3.25, 'train_speed(iter/s)': 0.343881, 'epoch': 0.26, 'global_step/max_steps': '120/462', 'percentage': '25.97%', 'elapsed_time': '5m 48s', 'remaining_time': '16m 33s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  27%|██▋       | 125/462 [06:02<15:50,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.48100319, 'acc': 0.86610785, 'grad_norm': 0.90798312, 'learning_rate': 8.744e-05, 'memory(GiB)': 3.25, 'train_speed(iter/s)': 0.344264, 'epoch': 0.27, 'global_step/max_steps': '125/462', 'percentage': '27.06%', 'elapsed_time': '6m 2s', 'remaining_time': '16m 18s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  28%|██▊       | 130/462 [06:16<15:26,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.39482653, 'acc': 0.8937439, 'grad_norm': 0.81374145, 'learning_rate': 8.623e-05, 'memory(GiB)': 3.25, 'train_speed(iter/s)': 0.344776, 'epoch': 0.28, 'global_step/max_steps': '130/462', 'percentage': '28.14%', 'elapsed_time': '6m 16s', 'remaining_time': '16m 2s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  29%|██▉       | 135/462 [06:30<15:06,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.44934692, 'acc': 0.87189255, 'grad_norm': 1.0380441, 'learning_rate': 8.497e-05, 'memory(GiB)': 4.29, 'train_speed(iter/s)': 0.345276, 'epoch': 0.29, 'global_step/max_steps': '135/462', 'percentage': '29.22%', 'elapsed_time': '6m 30s', 'remaining_time': '15m 46s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  30%|███       | 140/462 [06:44<14:56,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.44342308, 'acc': 0.87749319, 'grad_norm': 0.76591295, 'learning_rate': 8.367e-05, 'memory(GiB)': 4.29, 'train_speed(iter/s)': 0.345643, 'epoch': 0.3, 'global_step/max_steps': '140/462', 'percentage': '30.30%', 'elapsed_time': '6m 44s', 'remaining_time': '15m 30s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  31%|███▏      | 145/462 [06:58<14:37,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.45470243, 'acc': 0.86910038, 'grad_norm': 0.97608829, 'learning_rate': 8.232e-05, 'memory(GiB)': 4.29, 'train_speed(iter/s)': 0.346024, 'epoch': 0.31, 'global_step/max_steps': '145/462', 'percentage': '31.39%', 'elapsed_time': '6m 58s', 'remaining_time': '15m 15s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  32%|███▏      | 150/462 [07:12<14:21,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4540978, 'acc': 0.86919689, 'grad_norm': 0.9767282, 'learning_rate': 8.093e-05, 'memory(GiB)': 5.36, 'train_speed(iter/s)': 0.346508, 'epoch': 0.32, 'global_step/max_steps': '150/462', 'percentage': '32.47%', 'elapsed_time': '7m 12s', 'remaining_time': '14m 59s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100%|██████████| 74/74 [00:03<00:00, 20.55it/s]/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44738784, 'eval_acc': 0.86698142, 'eval_runtime': 3.5597, 'eval_samples_per_second': 20.788, 'eval_steps_per_second': 20.788, 'epoch': 0.32, 'global_step/max_steps': '150/462', 'percentage': '32.47%', 'elapsed_time': '7m 16s', 'remaining_time': '15m 7s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "[INFO:swift] Saving model checkpoint to /root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429/checkpoint-150\n",
      "Train:  34%|███▎      | 155/462 [07:31<15:48,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.39690335, 'acc': 0.8837882, 'grad_norm': 0.7612046, 'learning_rate': 7.951e-05, 'memory(GiB)': 5.36, 'train_speed(iter/s)': 0.343433, 'epoch': 0.34, 'global_step/max_steps': '155/462', 'percentage': '33.55%', 'elapsed_time': '7m 30s', 'remaining_time': '14m 53s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  35%|███▍      | 160/462 [07:45<14:20,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4511507, 'acc': 0.87748556, 'grad_norm': 0.88686621, 'learning_rate': 7.804e-05, 'memory(GiB)': 5.36, 'train_speed(iter/s)': 0.343753, 'epoch': 0.35, 'global_step/max_steps': '160/462', 'percentage': '34.63%', 'elapsed_time': '7m 45s', 'remaining_time': '14m 37s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  36%|███▌      | 165/462 [07:59<13:53,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.44010935, 'acc': 0.87279558, 'grad_norm': 0.81993908, 'learning_rate': 7.654e-05, 'memory(GiB)': 5.36, 'train_speed(iter/s)': 0.344062, 'epoch': 0.36, 'global_step/max_steps': '165/462', 'percentage': '35.71%', 'elapsed_time': '7m 59s', 'remaining_time': '14m 22s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  37%|███▋      | 170/462 [08:13<13:39,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.43185329, 'acc': 0.87980089, 'grad_norm': 0.79096407, 'learning_rate': 7.5e-05, 'memory(GiB)': 5.36, 'train_speed(iter/s)': 0.34434, 'epoch': 0.37, 'global_step/max_steps': '170/462', 'percentage': '36.80%', 'elapsed_time': '8m 13s', 'remaining_time': '14m 7s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  38%|███▊      | 175/462 [08:27<13:14,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.48183436, 'acc': 0.86629438, 'grad_norm': 0.91397375, 'learning_rate': 7.343e-05, 'memory(GiB)': 5.36, 'train_speed(iter/s)': 0.344763, 'epoch': 0.38, 'global_step/max_steps': '175/462', 'percentage': '37.88%', 'elapsed_time': '8m 27s', 'remaining_time': '13m 51s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  39%|███▉      | 180/462 [08:41<13:18,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.47169733, 'acc': 0.86861687, 'grad_norm': 0.93128216, 'learning_rate': 7.183e-05, 'memory(GiB)': 5.36, 'train_speed(iter/s)': 0.344975, 'epoch': 0.39, 'global_step/max_steps': '180/462', 'percentage': '38.96%', 'elapsed_time': '8m 41s', 'remaining_time': '13m 36s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  40%|████      | 185/462 [08:55<12:54,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.47367945, 'acc': 0.87004833, 'grad_norm': 0.84356594, 'learning_rate': 7.021e-05, 'memory(GiB)': 5.36, 'train_speed(iter/s)': 0.345246, 'epoch': 0.4, 'global_step/max_steps': '185/462', 'percentage': '40.04%', 'elapsed_time': '8m 55s', 'remaining_time': '13m 21s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  41%|████      | 190/462 [09:09<12:39,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.40551424, 'acc': 0.88912659, 'grad_norm': 0.9212898, 'learning_rate': 6.855e-05, 'memory(GiB)': 5.36, 'train_speed(iter/s)': 0.345564, 'epoch': 0.41, 'global_step/max_steps': '190/462', 'percentage': '41.13%', 'elapsed_time': '9m 9s', 'remaining_time': '13m 6s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  42%|████▏     | 195/462 [09:23<12:15,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.41866422, 'acc': 0.87702904, 'grad_norm': 0.83646154, 'learning_rate': 6.688e-05, 'memory(GiB)': 5.36, 'train_speed(iter/s)': 0.345945, 'epoch': 0.42, 'global_step/max_steps': '195/462', 'percentage': '42.21%', 'elapsed_time': '9m 23s', 'remaining_time': '12m 51s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  43%|████▎     | 200/462 [09:37<12:03,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.42139664, 'acc': 0.88415709, 'grad_norm': 1.05838919, 'learning_rate': 6.518e-05, 'memory(GiB)': 5.36, 'train_speed(iter/s)': 0.346271, 'epoch': 0.43, 'global_step/max_steps': '200/462', 'percentage': '43.29%', 'elapsed_time': '9m 37s', 'remaining_time': '12m 36s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100%|██████████| 74/74 [00:03<00:00, 21.31it/s]/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44340181, 'eval_acc': 0.86872627, 'eval_runtime': 3.4747, 'eval_samples_per_second': 21.297, 'eval_steps_per_second': 21.297, 'epoch': 0.43, 'global_step/max_steps': '200/462', 'percentage': '43.29%', 'elapsed_time': '9m 40s', 'remaining_time': '12m 40s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "[INFO:swift] Saving model checkpoint to /root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429/checkpoint-200\n",
      "Train:  44%|████▍     | 205/462 [09:55<13:17,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.42414532, 'acc': 0.87762299, 'grad_norm': 0.8267619, 'learning_rate': 6.346e-05, 'memory(GiB)': 5.36, 'train_speed(iter/s)': 0.343862, 'epoch': 0.44, 'global_step/max_steps': '205/462', 'percentage': '44.37%', 'elapsed_time': '9m 55s', 'remaining_time': '12m 26s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  45%|████▌     | 210/462 [10:09<11:56,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.43905234, 'acc': 0.87239313, 'grad_norm': 0.88912994, 'learning_rate': 6.172e-05, 'memory(GiB)': 5.36, 'train_speed(iter/s)': 0.344119, 'epoch': 0.45, 'global_step/max_steps': '210/462', 'percentage': '45.45%', 'elapsed_time': '10m 9s', 'remaining_time': '12m 11s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  47%|████▋     | 215/462 [10:24<11:38,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.42614274, 'acc': 0.87787828, 'grad_norm': 0.8290385, 'learning_rate': 5.997e-05, 'memory(GiB)': 5.36, 'train_speed(iter/s)': 0.344339, 'epoch': 0.46, 'global_step/max_steps': '215/462', 'percentage': '46.54%', 'elapsed_time': '10m 24s', 'remaining_time': '11m 56s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  48%|████▊     | 220/462 [10:38<11:12,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.41509504, 'acc': 0.88102503, 'grad_norm': 0.87730086, 'learning_rate': 5.821e-05, 'memory(GiB)': 5.36, 'train_speed(iter/s)': 0.344622, 'epoch': 0.48, 'global_step/max_steps': '220/462', 'percentage': '47.62%', 'elapsed_time': '10m 38s', 'remaining_time': '11m 41s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  49%|████▊     | 225/462 [10:52<11:01,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.45513611, 'acc': 0.87567902, 'grad_norm': 0.68040472, 'learning_rate': 5.644e-05, 'memory(GiB)': 5.36, 'train_speed(iter/s)': 0.344855, 'epoch': 0.49, 'global_step/max_steps': '225/462', 'percentage': '48.70%', 'elapsed_time': '10m 52s', 'remaining_time': '11m 26s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  50%|████▉     | 230/462 [11:06<10:49,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.44402838, 'acc': 0.87901001, 'grad_norm': 0.88692886, 'learning_rate': 5.466e-05, 'memory(GiB)': 5.36, 'train_speed(iter/s)': 0.345067, 'epoch': 0.5, 'global_step/max_steps': '230/462', 'percentage': '49.78%', 'elapsed_time': '11m 6s', 'remaining_time': '11m 11s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  51%|█████     | 235/462 [11:20<10:33,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.46622286, 'acc': 0.86730671, 'grad_norm': 0.92842913, 'learning_rate': 5.287e-05, 'memory(GiB)': 5.36, 'train_speed(iter/s)': 0.345296, 'epoch': 0.51, 'global_step/max_steps': '235/462', 'percentage': '50.87%', 'elapsed_time': '11m 20s', 'remaining_time': '10m 57s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  52%|█████▏    | 240/462 [11:34<10:19,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.39747093, 'acc': 0.88348618, 'grad_norm': 0.84517038, 'learning_rate': 5.108e-05, 'memory(GiB)': 5.36, 'train_speed(iter/s)': 0.345488, 'epoch': 0.52, 'global_step/max_steps': '240/462', 'percentage': '51.95%', 'elapsed_time': '11m 34s', 'remaining_time': '10m 42s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  53%|█████▎    | 245/462 [11:48<10:07,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.40088949, 'acc': 0.88557453, 'grad_norm': 0.78929359, 'learning_rate': 4.928e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.345648, 'epoch': 0.53, 'global_step/max_steps': '245/462', 'percentage': '53.03%', 'elapsed_time': '11m 48s', 'remaining_time': '10m 27s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  54%|█████▍    | 250/462 [12:02<09:52,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4196878, 'acc': 0.87997398, 'grad_norm': 1.03608644, 'learning_rate': 4.749e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.34587, 'epoch': 0.54, 'global_step/max_steps': '250/462', 'percentage': '54.11%', 'elapsed_time': '12m 2s', 'remaining_time': '10m 12s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100%|██████████| 74/74 [00:03<00:00, 20.77it/s]/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.44020447, 'eval_acc': 0.86965001, 'eval_runtime': 3.5521, 'eval_samples_per_second': 20.833, 'eval_steps_per_second': 20.833, 'epoch': 0.54, 'global_step/max_steps': '250/462', 'percentage': '54.11%', 'elapsed_time': '12m 6s', 'remaining_time': '10m 15s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "[INFO:swift] Saving model checkpoint to /root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429/checkpoint-250\n",
      "Train:  55%|█████▌    | 255/462 [12:21<10:53,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.40466113, 'acc': 0.88457556, 'grad_norm': 1.01353824, 'learning_rate': 4.57e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.343713, 'epoch': 0.55, 'global_step/max_steps': '255/462', 'percentage': '55.19%', 'elapsed_time': '12m 21s', 'remaining_time': '10m 1s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  56%|█████▋    | 260/462 [12:35<09:37,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.43538513, 'acc': 0.87554073, 'grad_norm': 0.76405221, 'learning_rate': 4.392e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.343935, 'epoch': 0.56, 'global_step/max_steps': '260/462', 'percentage': '56.28%', 'elapsed_time': '12m 35s', 'remaining_time': '9m 47s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  57%|█████▋    | 265/462 [12:49<09:12,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.42398634, 'acc': 0.87528315, 'grad_norm': 0.89756083, 'learning_rate': 4.214e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.344129, 'epoch': 0.57, 'global_step/max_steps': '265/462', 'percentage': '57.36%', 'elapsed_time': '12m 49s', 'remaining_time': '9m 32s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  58%|█████▊    | 270/462 [13:03<08:55,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.41076317, 'acc': 0.88450174, 'grad_norm': 0.83872974, 'learning_rate': 4.038e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.344344, 'epoch': 0.58, 'global_step/max_steps': '270/462', 'percentage': '58.44%', 'elapsed_time': '13m 3s', 'remaining_time': '9m 17s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  60%|█████▉    | 275/462 [13:17<08:37,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.48236232, 'acc': 0.86480303, 'grad_norm': 1.00179327, 'learning_rate': 3.862e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.34461, 'epoch': 0.59, 'global_step/max_steps': '275/462', 'percentage': '59.52%', 'elapsed_time': '13m 17s', 'remaining_time': '9m 2s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  61%|██████    | 280/462 [13:31<08:22,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.44441042, 'acc': 0.87482719, 'grad_norm': 1.00647306, 'learning_rate': 3.689e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.344853, 'epoch': 0.61, 'global_step/max_steps': '280/462', 'percentage': '60.61%', 'elapsed_time': '13m 31s', 'remaining_time': '8m 47s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  62%|██████▏   | 285/462 [13:45<08:09,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.38297296, 'acc': 0.88957491, 'grad_norm': 0.83786893, 'learning_rate': 3.516e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.345071, 'epoch': 0.62, 'global_step/max_steps': '285/462', 'percentage': '61.69%', 'elapsed_time': '13m 45s', 'remaining_time': '8m 32s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  63%|██████▎   | 290/462 [13:59<07:57,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.40660067, 'acc': 0.87633524, 'grad_norm': 0.86365932, 'learning_rate': 3.346e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.345296, 'epoch': 0.63, 'global_step/max_steps': '290/462', 'percentage': '62.77%', 'elapsed_time': '13m 59s', 'remaining_time': '8m 17s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  64%|██████▍   | 295/462 [14:13<07:44,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.40582957, 'acc': 0.88830137, 'grad_norm': 0.84162724, 'learning_rate': 3.178e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.345502, 'epoch': 0.64, 'global_step/max_steps': '295/462', 'percentage': '63.85%', 'elapsed_time': '14m 13s', 'remaining_time': '8m 3s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  65%|██████▍   | 300/462 [14:27<07:29,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4449903, 'acc': 0.87143526, 'grad_norm': 0.83260709, 'learning_rate': 3.012e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.345687, 'epoch': 0.65, 'global_step/max_steps': '300/462', 'percentage': '64.94%', 'elapsed_time': '14m 27s', 'remaining_time': '7m 48s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100%|██████████| 74/74 [00:03<00:00, 20.35it/s]/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4376891, 'eval_acc': 0.87026583, 'eval_runtime': 3.6171, 'eval_samples_per_second': 20.458, 'eval_steps_per_second': 20.458, 'epoch': 0.65, 'global_step/max_steps': '300/462', 'percentage': '64.94%', 'elapsed_time': '14m 31s', 'remaining_time': '7m 50s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "[INFO:swift] Saving model checkpoint to /root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429/checkpoint-300\n",
      "Train:  66%|██████▌   | 305/462 [14:46<08:07,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4477201, 'acc': 0.87735186, 'grad_norm': 0.88744503, 'learning_rate': 2.849e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.344087, 'epoch': 0.66, 'global_step/max_steps': '305/462', 'percentage': '66.02%', 'elapsed_time': '14m 46s', 'remaining_time': '7m 36s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  67%|██████▋   | 310/462 [15:00<07:10,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.38456025, 'acc': 0.89157305, 'grad_norm': 0.86914623, 'learning_rate': 2.689e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.344284, 'epoch': 0.67, 'global_step/max_steps': '310/462', 'percentage': '67.10%', 'elapsed_time': '15m 0s', 'remaining_time': '7m 21s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  68%|██████▊   | 315/462 [15:14<06:49,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.43926272, 'acc': 0.87863998, 'grad_norm': 0.85795516, 'learning_rate': 2.531e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.344499, 'epoch': 0.68, 'global_step/max_steps': '315/462', 'percentage': '68.18%', 'elapsed_time': '15m 14s', 'remaining_time': '7m 6s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  69%|██████▉   | 320/462 [15:28<06:42,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.43764243, 'acc': 0.87474461, 'grad_norm': 0.84792829, 'learning_rate': 2.377e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.344611, 'epoch': 0.69, 'global_step/max_steps': '320/462', 'percentage': '69.26%', 'elapsed_time': '15m 28s', 'remaining_time': '6m 51s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  70%|███████   | 325/462 [15:43<06:34,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.41729293, 'acc': 0.87732449, 'grad_norm': 1.03248012, 'learning_rate': 2.226e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.344524, 'epoch': 0.7, 'global_step/max_steps': '325/462', 'percentage': '70.35%', 'elapsed_time': '15m 42s', 'remaining_time': '6m 37s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  71%|███████▏  | 330/462 [15:57<06:08,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.43344598, 'acc': 0.87657528, 'grad_norm': 0.98176873, 'learning_rate': 2.079e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.344715, 'epoch': 0.71, 'global_step/max_steps': '330/462', 'percentage': '71.43%', 'elapsed_time': '15m 56s', 'remaining_time': '6m 22s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  73%|███████▎  | 335/462 [16:10<05:52,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.45383439, 'acc': 0.87211895, 'grad_norm': 1.00486231, 'learning_rate': 1.935e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.344901, 'epoch': 0.72, 'global_step/max_steps': '335/462', 'percentage': '72.51%', 'elapsed_time': '16m 10s', 'remaining_time': '6m 8s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  74%|███████▎  | 340/462 [16:25<06:04,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.37483313, 'acc': 0.89192867, 'grad_norm': 0.93388575, 'learning_rate': 1.795e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.344725, 'epoch': 0.74, 'global_step/max_steps': '340/462', 'percentage': '73.59%', 'elapsed_time': '16m 25s', 'remaining_time': '5m 53s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  75%|███████▍  | 345/462 [16:40<05:32,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.42937264, 'acc': 0.8813839, 'grad_norm': 1.0539397, 'learning_rate': 1.66e-05, 'memory(GiB)': 6.45, 'train_speed(iter/s)': 0.34486, 'epoch': 0.75, 'global_step/max_steps': '345/462', 'percentage': '74.68%', 'elapsed_time': '16m 40s', 'remaining_time': '5m 39s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  76%|███████▌  | 350/462 [16:54<05:14,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.40393028, 'acc': 0.88046932, 'grad_norm': 0.85154933, 'learning_rate': 1.528e-05, 'memory(GiB)': 7.55, 'train_speed(iter/s)': 0.344999, 'epoch': 0.76, 'global_step/max_steps': '350/462', 'percentage': '75.76%', 'elapsed_time': '16m 54s', 'remaining_time': '5m 24s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100%|██████████| 74/74 [00:03<00:00, 20.91it/s]/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43777975, 'eval_acc': 0.86995792, 'eval_runtime': 3.5303, 'eval_samples_per_second': 20.961, 'eval_steps_per_second': 20.961, 'epoch': 0.76, 'global_step/max_steps': '350/462', 'percentage': '75.76%', 'elapsed_time': '16m 57s', 'remaining_time': '5m 25s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "[INFO:swift] Saving model checkpoint to /root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429/checkpoint-350\n",
      "Train:  77%|███████▋  | 355/462 [17:12<05:36,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.41759043, 'acc': 0.88197184, 'grad_norm': 0.96114713, 'learning_rate': 1.402e-05, 'memory(GiB)': 7.55, 'train_speed(iter/s)': 0.343581, 'epoch': 0.77, 'global_step/max_steps': '355/462', 'percentage': '76.84%', 'elapsed_time': '17m 12s', 'remaining_time': '5m 11s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  78%|███████▊  | 360/462 [17:26<04:48,  2.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.44254646, 'acc': 0.87168818, 'grad_norm': 0.96762151, 'learning_rate': 1.279e-05, 'memory(GiB)': 7.55, 'train_speed(iter/s)': 0.343785, 'epoch': 0.78, 'global_step/max_steps': '360/462', 'percentage': '77.92%', 'elapsed_time': '17m 26s', 'remaining_time': '4m 56s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  79%|███████▉  | 365/462 [17:40<04:29,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.46085806, 'acc': 0.87282066, 'grad_norm': 0.99597031, 'learning_rate': 1.162e-05, 'memory(GiB)': 7.55, 'train_speed(iter/s)': 0.343967, 'epoch': 0.79, 'global_step/max_steps': '365/462', 'percentage': '79.00%', 'elapsed_time': '17m 40s', 'remaining_time': '4m 41s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  80%|████████  | 370/462 [17:54<04:14,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.39014974, 'acc': 0.88847075, 'grad_norm': 0.94709653, 'learning_rate': 1.05e-05, 'memory(GiB)': 7.55, 'train_speed(iter/s)': 0.344162, 'epoch': 0.8, 'global_step/max_steps': '370/462', 'percentage': '80.09%', 'elapsed_time': '17m 54s', 'remaining_time': '4m 27s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  81%|████████  | 375/462 [18:09<04:04,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4033742, 'acc': 0.88656559, 'grad_norm': 0.8539477, 'learning_rate': 9.42e-06, 'memory(GiB)': 7.55, 'train_speed(iter/s)': 0.344253, 'epoch': 0.81, 'global_step/max_steps': '375/462', 'percentage': '81.17%', 'elapsed_time': '18m 9s', 'remaining_time': '4m 12s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  82%|████████▏ | 380/462 [18:23<03:49,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.40679183, 'acc': 0.88613443, 'grad_norm': 0.84505373, 'learning_rate': 8.4e-06, 'memory(GiB)': 7.55, 'train_speed(iter/s)': 0.344385, 'epoch': 0.82, 'global_step/max_steps': '380/462', 'percentage': '82.25%', 'elapsed_time': '18m 23s', 'remaining_time': '3m 58s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  83%|████████▎ | 385/462 [18:37<03:35,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.40197597, 'acc': 0.88090611, 'grad_norm': 1.01427925, 'learning_rate': 7.43e-06, 'memory(GiB)': 8.31, 'train_speed(iter/s)': 0.344476, 'epoch': 0.83, 'global_step/max_steps': '385/462', 'percentage': '83.33%', 'elapsed_time': '18m 37s', 'remaining_time': '3m 43s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  84%|████████▍ | 390/462 [18:51<03:20,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.43132739, 'acc': 0.87566309, 'grad_norm': 0.98452187, 'learning_rate': 6.52e-06, 'memory(GiB)': 2.4, 'train_speed(iter/s)': 0.344633, 'epoch': 0.84, 'global_step/max_steps': '390/462', 'percentage': '84.42%', 'elapsed_time': '18m 51s', 'remaining_time': '3m 28s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  85%|████████▌ | 395/462 [19:05<03:12,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.40652628, 'acc': 0.87975693, 'grad_norm': 0.76527208, 'learning_rate': 5.66e-06, 'memory(GiB)': 2.4, 'train_speed(iter/s)': 0.344692, 'epoch': 0.85, 'global_step/max_steps': '395/462', 'percentage': '85.50%', 'elapsed_time': '19m 5s', 'remaining_time': '3m 14s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  87%|████████▋ | 400/462 [19:19<02:53,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.42356701, 'acc': 0.8779748, 'grad_norm': 0.75377649, 'learning_rate': 4.86e-06, 'memory(GiB)': 2.4, 'train_speed(iter/s)': 0.344826, 'epoch': 0.86, 'global_step/max_steps': '400/462', 'percentage': '86.58%', 'elapsed_time': '19m 19s', 'remaining_time': '2m 59s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100%|██████████| 74/74 [00:03<00:00, 20.63it/s]/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43722194, 'eval_acc': 0.86954737, 'eval_runtime': 3.5577, 'eval_samples_per_second': 20.8, 'eval_steps_per_second': 20.8, 'epoch': 0.86, 'global_step/max_steps': '400/462', 'percentage': '86.58%', 'elapsed_time': '19m 23s', 'remaining_time': '3m 0s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "[INFO:swift] Saving model checkpoint to /root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429/checkpoint-400\n",
      "Train:  88%|████████▊ | 405/462 [19:38<03:01,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.41375279, 'acc': 0.88059292, 'grad_norm': 0.87284458, 'learning_rate': 4.12e-06, 'memory(GiB)': 2.4, 'train_speed(iter/s)': 0.343584, 'epoch': 0.88, 'global_step/max_steps': '405/462', 'percentage': '87.66%', 'elapsed_time': '19m 38s', 'remaining_time': '2m 45s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  89%|████████▊ | 410/462 [19:52<02:30,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.41930542, 'acc': 0.87877216, 'grad_norm': 0.8474654, 'learning_rate': 3.44e-06, 'memory(GiB)': 2.4, 'train_speed(iter/s)': 0.343592, 'epoch': 0.89, 'global_step/max_steps': '410/462', 'percentage': '88.74%', 'elapsed_time': '19m 52s', 'remaining_time': '2m 31s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  90%|████████▉ | 415/462 [20:06<02:11,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.42810163, 'acc': 0.87611351, 'grad_norm': 0.85608298, 'learning_rate': 2.81e-06, 'memory(GiB)': 2.4, 'train_speed(iter/s)': 0.343759, 'epoch': 0.9, 'global_step/max_steps': '415/462', 'percentage': '89.83%', 'elapsed_time': '20m 6s', 'remaining_time': '2m 16s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  91%|█████████ | 420/462 [20:20<01:57,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.40582781, 'acc': 0.88450832, 'grad_norm': 0.90657645, 'learning_rate': 2.25e-06, 'memory(GiB)': 2.4, 'train_speed(iter/s)': 0.343911, 'epoch': 0.91, 'global_step/max_steps': '420/462', 'percentage': '90.91%', 'elapsed_time': '20m 20s', 'remaining_time': '2m 2s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  92%|█████████▏| 425/462 [20:35<01:47,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.43628626, 'acc': 0.87747288, 'grad_norm': 0.84353089, 'learning_rate': 1.75e-06, 'memory(GiB)': 2.4, 'train_speed(iter/s)': 0.343838, 'epoch': 0.92, 'global_step/max_steps': '425/462', 'percentage': '91.99%', 'elapsed_time': '20m 35s', 'remaining_time': '1m 47s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  93%|█████████▎| 430/462 [20:50<01:34,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.48727078, 'acc': 0.8668726, 'grad_norm': 0.91388267, 'learning_rate': 1.31e-06, 'memory(GiB)': 2.4, 'train_speed(iter/s)': 0.343737, 'epoch': 0.93, 'global_step/max_steps': '430/462', 'percentage': '93.07%', 'elapsed_time': '20m 50s', 'remaining_time': '1m 33s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  94%|█████████▍| 435/462 [21:05<01:18,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.43495641, 'acc': 0.87271986, 'grad_norm': 0.85459065, 'learning_rate': 9.3e-07, 'memory(GiB)': 2.4, 'train_speed(iter/s)': 0.343614, 'epoch': 0.94, 'global_step/max_steps': '435/462', 'percentage': '94.16%', 'elapsed_time': '21m 5s', 'remaining_time': '1m 18s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  95%|█████████▌| 440/462 [21:19<01:02,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.47182937, 'acc': 0.86950817, 'grad_norm': 0.96713126, 'learning_rate': 6.2e-07, 'memory(GiB)': 2.4, 'train_speed(iter/s)': 0.343685, 'epoch': 0.95, 'global_step/max_steps': '440/462', 'percentage': '95.24%', 'elapsed_time': '21m 19s', 'remaining_time': '1m 3s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  96%|█████████▋| 445/462 [21:33<00:47,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.41961122, 'acc': 0.8789732, 'grad_norm': 0.97197586, 'learning_rate': 3.7e-07, 'memory(GiB)': 2.4, 'train_speed(iter/s)': 0.343861, 'epoch': 0.96, 'global_step/max_steps': '445/462', 'percentage': '96.32%', 'elapsed_time': '21m 33s', 'remaining_time': '49s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  97%|█████████▋| 450/462 [21:47<00:33,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.42666392, 'acc': 0.88467884, 'grad_norm': 0.86686599, 'learning_rate': 1.9e-07, 'memory(GiB)': 2.4, 'train_speed(iter/s)': 0.344039, 'epoch': 0.97, 'global_step/max_steps': '450/462', 'percentage': '97.40%', 'elapsed_time': '21m 47s', 'remaining_time': '34s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Val: 100%|██████████| 74/74 [00:03<00:00, 21.03it/s]/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43659654, 'eval_acc': 0.86954737, 'eval_runtime': 3.5105, 'eval_samples_per_second': 21.08, 'eval_steps_per_second': 21.08, 'epoch': 0.97, 'global_step/max_steps': '450/462', 'percentage': '97.40%', 'elapsed_time': '21m 51s', 'remaining_time': '34s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "[INFO:swift] Saving model checkpoint to /root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429/checkpoint-450\n",
      "Train:  98%|█████████▊| 455/462 [22:06<00:21,  3.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.41813192, 'acc': 0.88008442, 'grad_norm': 0.86753607, 'learning_rate': 6e-08, 'memory(GiB)': 2.4, 'train_speed(iter/s)': 0.343032, 'epoch': 0.98, 'global_step/max_steps': '455/462', 'percentage': '98.48%', 'elapsed_time': '22m 6s', 'remaining_time': '20s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|█████████▉| 460/462 [22:19<00:05,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.43385692, 'acc': 0.87394648, 'grad_norm': 0.89694482, 'learning_rate': 1e-08, 'memory(GiB)': 2.4, 'train_speed(iter/s)': 0.343202, 'epoch': 0.99, 'global_step/max_steps': '460/462', 'percentage': '99.57%', 'elapsed_time': '22m 19s', 'remaining_time': '5s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: 100%|██████████| 462/462 [22:25<00:00,  2.80s/it]\n",
      "Val: 100%|██████████| 74/74 [00:03<00:00, 21.11it/s]/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43656504, 'eval_acc': 0.86965001, 'eval_runtime': 3.4886, 'eval_samples_per_second': 21.212, 'eval_steps_per_second': 21.212, 'epoch': 1.0, 'global_step/max_steps': '462/462', 'percentage': '100.00%', 'elapsed_time': '22m 29s', 'remaining_time': '0s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n",
      "[INFO:swift] Saving model checkpoint to /root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429/checkpoint-462\n",
      "Train: 100%|██████████| 462/462 [22:30<00:00,  2.92s/it]\n",
      "[INFO:swift] last_model_checkpoint: /root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429/checkpoint-462\n",
      "[INFO:swift] best_model_checkpoint: /root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429/checkpoint-462\n",
      "[INFO:swift] images_dir: /root/autodl-fs/code/nlp_pj/pj6/output/qwen2_5-0_5b-instruct/v1-20241125-232429/images\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1349.9878, 'train_samples_per_second': 5.481, 'train_steps_per_second': 0.342, 'train_loss': 0.44557389, 'epoch': 1.0, 'global_step/max_steps': '462/462', 'percentage': '100.00%', 'elapsed_time': '22m 30s', 'remaining_time': '0s'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO:swift] End time of running main: 2024-11-25 23:47:16.806765\n"
     ]
    }
   ],
   "source": [
    "model_type = ModelType.qwen2_5_0_5b_instruct\n",
    "sft_args = SftArguments(\n",
    "    model_type=model_type,\n",
    "    dataset=['gsm8k-train.jsonl'],\n",
    "    output_dir='output',\n",
    "    max_length=4096)\n",
    "result = sft_main(sft_args)\n",
    "last_model_checkpoint = result['last_model_checkpoint']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
